\section{Introduction} \label{sec:intro}
Spatial processes are employed in many fields, such as geology, Earth science, environmental and agricultural surveys, among many others. A large variety of data is surveyed in space, such as rainfall \citep{ord1979spatial}, atmospheric  \citep{thiebaux1987spatial}, forestry  \citep{samra1989spatial} and soil data \citep{burgess1980optimal}, in order to perform statistical inference on parameters of interest. In these applications, a general approach is to postulate a spatial process for the variable $\Signal$ under investigation, that is a stochastic process is assumed to have generated the population values, also called \emph{superpopulation} model. %Such process is usually parametric, i.e. characterized by a finite number of parameters $\boldsymbol{\theta}$, and the interest is on inference about such parameters. If we use sample data in order to make inference about $\boldsymbol{\theta}$,
When using sample data, we need to pay attention to the relation between the spatial process and the  selection mechanism. Indeed, the distribution of the observed data can be different from the distribution assumed for the population by means of the spatial process $P^{\Signal}$. In other words, the density obtained by the sample data may not be the density obtained by reducing the number of terms in $P^{\Signal}$, as if the units were selected completely at random. In this case, we say that the sampling is \emph{informative}. Ignoring an informative sample may lead to bias and erroneous inference, as illustrated for example in \cite{skinner1989analysis}. This could happen when there is dependence between the assumed stochastic model and the sampling mechanism, that is the units are selected dependently to the variable of interest. Examples of this type of mechanism selection are, among many others, length-biased sampling, endogenous stratification, adaptive sampling, sequential quota sampling, and cut-off sampling. For more details, see Section 3 of \cite{bonnery2012uniform}.

In this paper, we study the effect of informative selection when a spatial process is employed. We consider informative selection as a situation where the sample responses, \emph{given that they were selected}, are not i.i.d. from the superpopulation model. We start from the notion of population and sample distribution defined by \cite{pfefferman_1992}, and we extend those to a spatial process context. Indeed, \cite{pfefferman_1992} consider realizations of a random process of interest as independent and identically distributed, whereas we address the dependence between the realizations, which very likely characterizes a spatial process. As in \cite{pfeffermann1998parametric}, we start from the distribution of the observed values given they were selected, or \emph{sample pdf}. While \cite{pfeffermann1998parametric} consider the observations as if they were independently distributed according to the sample pdf, our work considers the dependence between the observed units in order to account for the spatial component of the population. Also, while \cite{pfeffermann1998parametric} assume that the target population $U$ is finite, our work can be applied to both finite population and continuous populations.

Throughout the paper we assume to have a spatial Gaussian process and a point process that represents the selection mechanism. Given these two processes, we then define the probability density function of the sample and a subsample, and the ``sample'' and ``population'' distribution of the signal. These concepts are needed in order to introduce a \emph{density ratio} that we use for investigating the bias possibly introduced by the selection mechanism, or \emph{selection bias}. In doing that, the spatial structure of the population is taken into account.

These general definitions allow us to define the sample counterpart of different characteristics of the population distribution. Indeed, we focus on the \emph{variogram}, which analyzes the degree of spatial dependence of spatial processes and provides useful insights on the phenomenon under investigation. For instance, the variogram is the key component for the well-known \emph{kriging} method \citep{matheron1962traite}, and it plays a crucial role on prediction since it is used to compute the kriging weights. We introduce the definitions of \emph{population variogram} and \emph{sample variogram}, and we investigate the behaviour of the \emph{naive} estimator, i.e. the estimator that does not take into account the informativeness of the selection mechanism.
%In this paper, we study the effect of informative selection when the variogram is of interest. We consider informative selection as a situation where the sample responses, given that they were selected, are not i.i.d. from the superpopulation model. As in \cite{pfeffermann1998parametric}, we start from the distribution of the observed values given they were selected, or \emph{sample pdf}. The major difference in our approach is that, while \cite{pfeffermann1998parametric} consider the observations as if they were independently distributed according to the sample pdf, our work consider the dependence between the observed units. {\color{red}Indeed, \cite{pfeffermann1998parametric}  }We provide a theoretical background for the definitions of \emph{population variogram} and \emph{sample variogram}, and some properties of the \emph{naive} estimator, i.e. the estimator that does not take into account the informativeness of the selection mechanism.


The paper is organized as follow. In Section \ref{sec:stat_fra} we define the statistical framework used throughout the paper. In particular, general notions and the concepts of spatial process, sample, design and design variables are introduced. In Section \ref{sec:sampledistribution} the sample distribution and the population distribution are defined, and in Section \ref{sec:estimation} estimation of the variogram is briefly reviewed and a  simulation study is carried out in order to investigate the behaviour of the naive estimator. In Section \ref{sec:prediction} we provide the formula for the predictive distribution of the signal conditioned to observed values. Finally, Section \ref{sec:conclusions} provides conclusion and future research.

% The \emph{sample pdf} is defined as the conditional distribution of the random variable $\Signal$ given that it was selected. \cite{pfeffermann1998parametric} use a sample likelihood approach to inference for the superpopulation model, where the product of the sample pdfs is maximized, as if the responses were iid.

%The major approaches to analytic inference from survey data are all based on the likelihood concept. The maximum \emph{full-information} likelihood approach defines the likelihood as the probability of observing all the relevant data available \citep{breckling1994maximum} and the process that has to be accounted for is given by the joint distribution of the spatial process $\Signal$ and the selection mechanism, while the maximum \emph{sample-likelihood} focuses on the distribution of $\Signal$ given it was observed \citep{krieger1992maximum, pfeffermann1993role, pfeffermann1998parametric, pfeffermann1999parametric}, and if this conditional distribution differs from the marginal distribution of $\Signal$, selection bias is introduced and the mechanism selection is \emph{informative}.
 %Since just a portion of the population is observed, the relevant likelihood is given by $P^{I_{U},\Signal_{S}}=\int{P^{I_{U},\Signal_{U}}d\Signal_{U \backslash s}}$, which is usually different from $P^{S}=\int{P^{\Signal_{U}}d\Signal_{U \backslash s}}$.

%The major approaches to analytic inference from survey data are all based on the likelihood concept. The maximum \emph{full-information} likelihood approach defines the likelihood as the probability of observing all the relevant data available \citep{breckling1994maximum}. The process that has to be accounted for is given by the joint distribution of the spatial process $\Signal$ and the selection mechanism.%Since just a portion of the population is observed, the relevant likelihood is given by $P^{I_{U},\Signal_{S}}=\int{P^{I_{U},\Signal_{U}}d\Signal_{U \backslash s}}$, which is usually different from $P^{S}=\int{P^{\Signal_{U}}d\Signal_{U \backslash s}}$.
% \\ The maximum \emph{sample-likelihood} focuses on the distribution of $\Signal$ given it was observed \citep{krieger1992maximum, pfeffermann1993role, pfeffermann1998parametric, pfeffermann1999parametric}. If this conditional distribution differs from the marginal distribution of $\Signal$, selection bias is introduced and the mechanism selection is \emph{informative}.

