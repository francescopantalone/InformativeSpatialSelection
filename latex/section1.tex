\section{Introduction} \label{sec:intro}
Spatial processes are employed in many fields, like geology, Earth science, environmental and agricultural surveys, among many others. A huge variety of data can be employed, such as rainfall data \citep{ord1979spatial}, atmospheric data \citep{thiebaux1987spatial}, forestry data \citep{samra1989spatial} and soils data \citep{burgess1980optimal} {\color{red} FP: these references are a little bit old, so not sure if we can leave it}. In these applications, a general approach is to postulate a spatial process for the variable $\Signal$ under investigation, that is a stochastic process which is assumed to have generated the population values, also called \emph{superpopulation} model. %Such process is usually parametric, i.e. characterized by a finite number of parameters $\boldsymbol{\theta}$, and the interest is on inference about such parameters. If we use sample data in order to make inference about $\boldsymbol{\theta}$,
When using sample data, we need to pay attention at the relation between the spatial process and the mechanism selection. Indeed, the distribution of the observed data can be different from the distribution assumed for the population by means of the spatial process. In other words, the density obtained by the sample data may not be the density obtained by reducing the number of terms in $P^{\Signal}$, as if the units were selected completely at random. In this case, we say that the sampling is \emph{informative}. Ignoring an informative sample may lead to biases and erroneous inference, as illustrated for example in \cite{skinner1989analysis}. This could happen when there is dependence between the assumed stochastic model and the sampling mechanism, that is the units are selected dependently to the variable of interest. Examples of this type of mechanism selection are, among many others, length-biased sampling, endogenous stratification, adaptive sampling, sequential quota sampling and cut-off sampling. For more details, see Section 3 of \cite{bonnery2012uniform}.
\\ When dealing with spatial processes, an important tool is the \emph{variogram}, which analyzes the degree of spatial dependence of such processes and provides useful insights on the phenomenon under investigation. For instance, the variogram is the key component for the well-known \emph{kriging} method \citep{matheron1962traite}, and it plays a crucial role on prediction since it is used to compute the kriging weights. 
\\ In this paper, we study the effect of informative selection when the variogram is of interest. We consider informative selection as a situation where the sample responses, given that they were selected, are not i.i.d. from the superpopulation model. As in \cite{pfeffermann1998parametric}, we start from the distribution of the observed values given they were selected, or \emph{sample pdf}. The major difference in our approach is that, while \cite{pfeffermann1998parametric} consider the observations as if they were independently distributed according to the sample pdf, our work consider the dependence between the observed units. We provide a theoretical background for the definitions of \emph{population variogram} and \emph{sample variogram}, and some properties of the \emph{naive} estimator, i.e. the estimator that does not take into account the informativeness of the selection mechanism.
\\The paper is organized as follow. In Section \ref{sec:stat_fra} we define the statistical framework used throughout the paper. In particular, general notions and the concepts of spatial process, sample, design and design variables are introduced. In Section \ref{sec:sampledistribution} the sample distribution and the population distribution are defined, and in Section \ref{sec:estimation} estimation of the variogram is analyzed and properties of the naive estimator are presented. Finally, Section \ref{sec:con} provides conclusion and future research.

% The \emph{sample pdf} is defined as the conditional distribution of the random variable $\Signal$ given that it was selected. \cite{pfeffermann1998parametric} use a sample likelihood approach to inference for the superpopulation model, where the product of the sample pdfs is maximized, as if the responses were iid.

%The major approaches to analytic inference from survey data are all based on the likelihood concept. The maximum \emph{full-information} likelihood approach defines the likelihood as the probability of observing all the relevant data available \citep{breckling1994maximum} and the process that has to be accounted for is given by the joint distribution of the spatial process $\Signal$ and the selection mechanism, while the maximum \emph{sample-likelihood} focuses on the distribution of $\Signal$ given it was observed \citep{krieger1992maximum, pfeffermann1993role, pfeffermann1998parametric, pfeffermann1999parametric}, and if this conditional distribution differs from the marginal distribution of $\Signal$, selection bias is introduced and the mechanism selection is \emph{informative}.
 %Since just a portion of the population is observed, the relevant likelihood is given by $P^{I_{U},\Signal_{S}}=\int{P^{I_{U},\Signal_{U}}d\Signal_{U \backslash s}}$, which is usually different from $P^{S}=\int{P^{\Signal_{U}}d\Signal_{U \backslash s}}$.

%The major approaches to analytic inference from survey data are all based on the likelihood concept. The maximum \emph{full-information} likelihood approach defines the likelihood as the probability of observing all the relevant data available \citep{breckling1994maximum}. The process that has to be accounted for is given by the joint distribution of the spatial process $\Signal$ and the selection mechanism.%Since just a portion of the population is observed, the relevant likelihood is given by $P^{I_{U},\Signal_{S}}=\int{P^{I_{U},\Signal_{U}}d\Signal_{U \backslash s}}$, which is usually different from $P^{S}=\int{P^{\Signal_{U}}d\Signal_{U \backslash s}}$.
% \\ The maximum \emph{sample-likelihood} focuses on the distribution of $\Signal$ given it was observed \citep{krieger1992maximum, pfeffermann1993role, pfeffermann1998parametric, pfeffermann1999parametric}. If this conditional distribution differs from the marginal distribution of $\Signal$, selection bias is introduced and the mechanism selection is \emph{informative}.

